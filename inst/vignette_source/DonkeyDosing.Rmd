---
title: "A guide to using the DonkeyDosing package"
author: "Matt Denwood"
date: "`r Sys.Date()`"
output: html_document
---

```{r include=FALSE}
set.seed(2023-05-18)
library("pbapply")
pboptions(type="none")
```


## Introduction

---

The DonkeyDosing package is an R package that supports the anthelmintic dosing protocol being used by the Donkey Sanctuary, Devon.  There are three primary uses for this package:

1.  To help generate updated weather data in the correct format on a weekly basis throughout the grazing season.  This requires a source of weather data, which should be generated by scraping on a daily basis.

1.  To update the dosing model every year in the spring.  This involves reading in historical data, new data from the previous year, weather data, and updating the coefficients used by the model.

1.  To facilitate creating a new dosing tool for the upcoming grazing season every year in the spring.  This involves extracting mean FEC for each animal observed from the previous year, and saving the new coefficient values to the correct sheet in the Excel file containing the dosing tool.

The package can either be installed directly from the public GitHub repository at http://github.com/ku-awdc/DonkeyDosing, or the latest stable version can be installed from our drat repository by running the following code:

```{r eval=FALSE}
install.packages("DonkeyDosing", 
    repos=c("https://cran.rstudio.com/","https://ku-awdc.github.io/drat/"))
```


---

## Generating weather data

---

### Scraping data

There are a number of free services for scraping recent weather data for arbitrary coordinates. Until recently, DarkSky was preferred, but this service has now closed down. One alternative is OpenWeather, although this is more limited than DarkSky in that data can only be obtained for the previous 5 days: this means that data must be scraped daily (or almost daily) in order to maintain a complete source of information.

A function is provided within the DonkeyDosing package to facilitate scraping.  The two input parameters are (1) the path to a folder where scraped data should be saved, and (2) an API key that has been set up via https://openweathermap.org/ (if this is omitted, then the key is assumed to be found in an "OpenWeatherKey.txt" file in the same folder as where the data is saved). The function can then be run as follows:

```{r}
ow_path <- "~/Documents/Resources/Datasets/DonkeyDosingWeather"

library("DonkeyDosing")
scrape_openweather(ow_path)
```

The daily weather observations are cached into a folder within the ow_path as follows:

```{r}
list.files(file.path(ow_path, "2022"))
```

As stated above, this function must be run daily (or almost daily) in order to ensure that an uninterrupted supply of weather data is obtained.  On linux this is best achieved using a CRON job, on macOS this can be done using launchd, and on Windows a scheduled task can be set up.

### Extracting data

During the grazing season, the formatted weather data will need to be extracted weekly so that the Dosing Model can be run using up-to-date weather data.  To do this, first ensure that the scraping function has been run as above.  Then run the extract_weather function as follows:

```{r}
weather <- extract_weather(ow_path, year="2023")
tail(weather)
```

This function extracts the information and formats as needed.  By default, cached information is taken from a "cache.csv" file in the ow_path directory where available, so that it only needs to be loaded from the daily .rds files once.  This means that the daily .rds files can be removed once they have been processed into the cache (and therefore that only the cache file needs to be transferred if the process is moved to another machine).

Note also that two mechanisms are provided for filling in missing data that may have occured due to a failure in scraping:

1.  The argument impute_missing=TRUE can be set, which uses a Kalman filter to impute missing observations and re-saves the cache with these imputed data.  This should be fine for the occasional missing day.

1.  The cache.csv file can be edited manually where necessary:  after running the function, days with missing observations appear in the correct place in the file but with missing data in the relevant columns.  This can simply be edited to correct the data manually using information from another source.

If the function runs successfully (i.e. all necessary data was found either in the cache or in scraped daily files) then a data frame will be returned.  This can then be saved as a CSV file and imported directly into the relevant sheet of the dosing tool.

```{r}
write.csv(weather, file=paste0('~/Dropbox/Donkey Sanctuary/weather_2022.csv'), row.names=FALSE)
```

Up to and including 2022, I have sent this file to Nikki automatically via email every Monday morning.  I will continue to do this for the forseable future, but it would be good for the Donkey Sanctuary to at least set up a parallel system so that there is some redundancy there.  Otherwise, let me know if/when I should stop sending the file.

### Adjustment for different weather services

For 2021 and earlier, the weather source used was from DarkSky.  Although obviously highly correlated, there are some small differences between DarkSky and OpenWeather that may have some influence on the dosing tool.  To illustrate this, we can use the period of data for which we have overlap (approximately 1 year from April 2021 to April 2022):

```{r}
openwthr <- extract_weather(ow_path, year="2022", include_date=TRUE) |>
	mutate(Source = "OpenWeather") |>
	select(-Year,-Week,-WeekDay,-Month,-Day) |>
	pivot_longer(Temp_high:Abs_Humidity_avg, names_to = "Variable", values_to = "Value")
	
darksky <- read_csv(file.path(ow_path, "dark_sky_comparison.csv"), show_col_types = FALSE) |>
	mutate(Source = "DarkSky") |>
	select(-Year,-Week,-WeekDay,-Month,-Day) |>
	pivot_longer(Temp_high:Abs_Humidity_avg, names_to = "Variable", values_to = "Value")

comb <- bind_rows(openwthr, darksky) |>
	pivot_wider(names_from = "Source", values_from = "Value") |> 
  filter(!is.na(OpenWeather), !is.na(DarkSky))

theme_set(theme_light())
ggplot(comb, aes(x=OpenWeather, y=DarkSky)) +
	geom_abline(slope=1, intercept=0) +
	stat_smooth(method="lm", formula=y~x) +
	geom_point() +
	facet_wrap(~ Variable, scales="free")
```

The absolute humidity and mean temperature are practically identical. For relative humidity there does seem to be some discrepancy at very low values, with DarkSky over-estimating relative to OpenWeather, but there are only a small number of points (around 4) in this area.  Similarly, DarkSky appears to slightly over-estimate the lowest minimum temperatures and slightly under-estimate the highest maximum temperatures relative to OpenWeather.  However, these differences are most likely too small to have any substantial affect on the model, so the switch from DarkSky for 2013-2021 towards OpenWeather for 2022 onwards should be safe to do.


---

## Updating the dosing model

---

The coefficients used within the dosing tool should be updated every spring, by refitting the model using the historical data plus new data that is available from the previous years' grazing history.  Functions are provided within the DonkeyDosing package to do this as follows.

### Checking and cleaning the new FEC data

Loading FEC from the previous year's grazing season must be done via the final (completed) Excel file containing the dosing tool from the previous year.  This data is collected in Excel over the grazing season and will not be checked for strict validation of inputs during the grazing season, so some level of data cleaning is usually necessary before the data can be read into R.  This obviously will vary from year to year, but the DonkeyDosing tool gives specific feedback about what errors need to be corrected.  Unfortunately, checking can only be done up to the first error detected, so the process must be run repeatedly with iterative correction of errors until the function completes successfully.  An example of this process is given here for the 2021 grazing season data.

First we must create an empty DonkeyDosing object and then set up a path to the directory containing the relevant Excel file (you will need to change this on your system):

```{r}
container <- DonkeyDosing()
dir <- "~/Documents/Research/Projects/Donkey Sanctuary 2/2022/"
```

Then we must add the locations that were used in 2021, by telling the DonkeyDosing tool to read the "Locations" sheet of the Excel file:

```{r}
container$AddLocations(2021, file.path(dir, "2021 Dosing Tool.xlsx"))
```

This typically runs without errors and did so for 2021.  We can then explicitly list the farms that are available in the data for reference:

```{r}
farms <- readxl::excel_sheets(file.path(dir, "2021 Dosing Tool.xlsx"))
farms <- farms[! farms %in% c("Overview","Locations", "WeatherData", "Advice", "Action List", "Data", "ModelData", "Data Selection", "MakeList", "Weather", "Coefficients", "EffectEstimates")]
farms
```

We must then add the data from the farms one at a time, as follows:

```{r}
container$AddDosingSheet(2021, "Axnoller", file.path(dir, "2021 Dosing Tool.xlsx"))
```

There is an error that must be corrected for Axnoller:  there are two columns with name "T20" (indicating which animals have been given anthelmintic treatment in week 20).  This must be corrected in the Excel file directly either by renaming one of the columns (if the column name is incorrect), or by merging the treatment information from both of the columns into a single column (using e.g. an Excel formula and then copying/pasting by value).  I suggest you first make a copy of the dosing tool and make modifications in the copy - here I append "cleaned" to the filename and then modified the T20 colum as outlined above.  Then we can try to re-read the file:

```{r}
container$AddDosingSheet(2021, "Axnoller", file.path(dir, "2021 Dosing Tool cleaned.xlsx"))
```

This time the function got further into the file before an error.  You can ignore the "New names:" and text below it: that just indicates that blank column names were given a temporary name, but these are ignored anyway.  However, some duplicated animal identifiers were found:  the dosing tool requires each animal to have exactly one row, so this needs to be fixed.  In this case the second entry for Winnie Belbin is blank, so can be deleted.  The second entry for Xavier Eire looks like a partial copy of the first, so can also be deleted. Then we can recheck the file:

```{r}
container$AddDosingSheet(2021, "Axnoller", file.path(dir, "2021 Dosing Tool cleaned 2.xlsx"))
```

[Note: in practice you would simply modify the "2021 Dosing Tool cleaned.xlsx" file, but for the sake of this vignette I will continue to copy the files first.]

This time the import worked.  Some messages are printed that we should look at:  firstly an invalid location was found and will be ignored.  In this case that is OK (as Pending is not a real location), but you should correct any typos in valid location names in the excel file.  You should also ensure that all of the text entries representing anthelmintic treatment really are anthelmintics - if any of these are notes then they should be deleted in the Excel file (or moved to a e.g. NXX column representing notes for the specific week).

Now that Axnoller is finalised, we can move on to Brookfield:

```{r}
container$AddDosingSheet(2021, "Brookfield", file.path(dir, "2021 Dosing Tool cleaned 2.xlsx"))
```

The only issue here is that "New Barn Bottom (Super Grannies)" is not recognised from the list of locations (on the Location sheet), because there it is spelt differently:  "New Barn Bottom (Super grannies)" (i.e. no capital g).  We therefore need to do a find and replace in the Brookfield sheet to correct this, and then re-run. However, our previous attempt did result in the Brookfield sheet being loaded, so we first need to reset the container to continue checking:

```{r}
container <- DonkeyDosing()
container$AddLocations(2021, file.path(dir, "2021 Dosing Tool.xlsx"))

container$AddDosingSheet(2021, "Brookfield", file.path(dir, "2021 Dosing Tool cleaned 3.xlsx"))
```

Now we can move on to Hurfords.

```{r}
container$AddDosingSheet(2021, "Hurfords", file.path(dir, "2021 Dosing Tool cleaned 3.xlsx"))
```

Nothing requires correcting here, so we can move straight on to Paccombe:

```{r}
container$AddDosingSheet(2021, "Paccombe", file.path(dir, "2021 Dosing Tool cleaned 3.xlsx"))
```

This is a similar error to before, but this time a single entry is in the second F11 column representing anthelmintic treatment - so the column name should be T11.  After fixing, we can re/run:

```{r}
container$AddDosingSheet(2021, "Paccombe", file.path(dir, "2021 Dosing Tool cleaned 4.xlsx"))
```

This time we can see some strange anthelmintic recordings:  these are mostly due to column K (T3), which has some real anthelmintic treatments (e.g. MOX) but also some dates (which presumably indicate MOX treatment on a slightly different date), and some entries that are not anthelmintic treatment (No Tx and ~).  The easiest thing to do is to copy this column, rename the original N3 and then tidy up the T3 column so that dates are switched to e.g. "Yes" (the text used doesn't actually matter) and non-treatment text is removed. Before re-running, we need to reset the container again:

```{r}
container <- DonkeyDosing()
container$AddLocations(2021, file.path(dir, "2021 Dosing Tool.xlsx"))

container$AddDosingSheet(2021, "Paccombe", file.path(dir, "2021 Dosing Tool cleaned 5.xlsx"))
```

Now we can move on to Slade:

```{r}
container$AddDosingSheet(2021, "Slade House Farm", file.path(dir, "2021 Dosing Tool cleaned 5.xlsx"))
```

The spelling variation for "Poitou back barn" should be corrected, and the container reset before rerunning:

```{r}
container <- DonkeyDosing()
container$AddLocations(2021, file.path(dir, "2021 Dosing Tool.xlsx"))

container$AddDosingSheet(2021, "Slade House Farm", file.path(dir, "2021 Dosing Tool cleaned 6.xlsx"))
```

Then we can move on to Town Barton:

```{r}
container$AddDosingSheet(2021, "Town Barton", file.path(dir, "2021 Dosing Tool cleaned 6.xlsx"))
```

And then Trow:

```{r}
container$AddDosingSheet(2021, "Trow", file.path(dir, "2021 Dosing Tool cleaned 6.xlsx"))
```

This time we get an error that there is no check date:  in order to verify week numbers at least entry must be made in the second row containing the date corresponding to the Monday of the week number in the first row. So here, we can enter 19/04/2021 as the date for week 16 in cell K2 and re-run:

```{r}
container$AddDosingSheet(2021, "Trow", file.path(dir, "2021 Dosing Tool cleaned 7.xlsx"))
```

The single location "Hurfords Far Hills" presumably represents an animal that was moved, so it should be ignored for Trow - so no action is needed.  So we can move on to Woods:

```{r}
container$AddDosingSheet(2021, "Woods", file.path(dir, "2021 Dosing Tool cleaned 7.xlsx"))
```

This is the same error as before:  the second F13 column contains anthelmintic treatments, so should be T13.  That is easily fixed:

```{r}
container$AddDosingSheet(2021, "Woods", file.path(dir, "2021 Dosing Tool cleaned 8.xlsx"))
```

A single asterix was used in cell Y132, which presumably does not represent anthelmintic treatment so can be removed. However, if you are unsure then you could always check with Nikki.

This time I will rename the file to "2021 Dosing Tool final.xlsx" and re-check:

```{r}
container <- DonkeyDosing()
container$AddLocations(2021, file.path(dir, "2021 Dosing Tool.xlsx"))

container$AddDosingSheet(2021, "Woods", file.path(dir, "2021 Dosing Tool final.xlsx"))
```

This completes without errors, which completes the checking phase.  If you encounter anything unexpected in future years then please feel free to email me!


### Loading the historical archive and weather data

Before we can update the model, we must populate the container using an archive file saved the previous spring.  It is best to start from a fresh container:

```{r}
container <- DonkeyDosing()
container$LoadDataArchive(file.path(dir, 'data_2013_2020.Rdata'))
```

We can now run the model to calculate coefficients, based on the historical data only (i.e. excluding this year's data). The default is to use at most 10 years of historical data (or as much as is available), but this can be changed by specifying the years argument manually if needed.  Then we can extract the coefficients from this archive for later comparison with the new estimates that will include this year's data. The following code runs several different models iteratively, so it takes a while (around 1 minute) to run:

```{r}
container$FitPredictionModel()
old_coefs <- container$GetCoefficients()
```

It is normal to get some warnings about "Model failed to converge with max|grad| = ..some small number.." - as long as these numbers are close to the reported tol (i.e. less than ~0.01) then it is OK.

Then we can load our newly cleaned file from the previous year:

```{r}
container$AddLocations(2021, file.path(dir, "2021 Dosing Tool.xlsx"))
for(f in farms){
  container$AddDosingSheet(2021, f, file.path(dir, "2021 Dosing Tool final.xlsx"))
}
```

This should complete successfully, but you should double check the output just in case!

Then we can add new weather data for the previous year to the dosing model container using the container method AddWeatherSheet:

```{r}
new_weather <- extract_weather(ow_path, year = "2021")
container$AddWeatherSheet(new_weather)
```

### Updating the coefficients

Now that we have the complete data entered including the most recent year, we can update the coefficients using the following code:

```{r}
container$FitPredictionModel()
coefs <- container$GetCoefficients()
```

As before, warnings about "Model failed to converge with max|grad| = ..some small number.." can be ignored as long as these numbers are close to the reported tol (i.e. less than ~0.01).

Now we have two sets of coefficients so it is a good idea to quickly compare them to see how much has changed:

```{r}
cbind(old_coefs, coefs)
```

Some of the parameters have shifted slightly, but the majority are very similar.


### Extracting information for clinical use

One useful side-effect of running the model is that we are able to compare predicted FEC to observed FEC at specific locations.  This allows us to assess if there are particular locations within a farm that have shown consistently high (or low) FEC compared to the expectation on a given year (accounting for average patterns on the farm, weather, pasture hygiene, etc).

To produce plots for one or more farms use the GetPlots function:

```{r}
container$GetPlots("Paccombe")
```

The default is to use the most recent year, but this can be changed using the year argument.  To save plots to file specify a file argument (ending with ".pdf"), and optionally other arguments that are passed to the pdf function - this also allows multiple farms and/or years to be saved on different pages:

```{r}
container$GetPlots(farm="all", year="latest", file="plots.pdf", width=8, height=8)
```


There are two caveats with these comparisons:

1. The expectation does not take into account animal-level factors such as age, breed, FEC history and treatment history, so a consistently low FEC could be caused by e.g. unusually high frequency of anthelmintic dosing.

1. The average FEC is calculated based on different numbers of animals, so large deviations from the expected level are more likely to be due to chance for small group sizes. This can be assessed by looking at the average number of FEC observations represented per data point, which is shown in brackets after the name of the location (in the facet title).

This information may be useful for consideration by the veterinary team as part of the annual assessment of parasite control in these groups, but as always it should be interpreted in the context of the clinical status of the animals.


### Saving the data archive

The final step of updating the dosing model is to save the data archive so that it can be quickly loaded next spring:

```{r eval=FALSE}
container$SaveDataArchive(file.path(dir, 'data_2013_2021.Rdata'))
```


---

## Creating the dosing tool for the upcoming grazing season

---

### Automatically extracting new data

Part of the process of updating the dosing tool with animal ages and mean FEC can be automated, using the update_dosing_tool function provided:

```{r}
new_sheets <- update_dosing_tool(excel_file = file.path(dir, "2021 Dosing Tool final.xlsx"),
                                 weather_path = ow_path,
                                 year = "2022",
                                 coefficients = coefs,
                                 output_file = "dosing_sheets_2022.xlsx")
```

This function extracts information about the available animals from the previous year's dosing tool, including calculating their average observed FEC and incrementing their age by 1 year, and then combines this with the weather data and coefficients in the right format.  Note that the required first argument is the final (cleaned) dosing tool from the previous year, and the year specified is the year for the new dosing tool i.e. for the current year.


### Integrating into the dosing tool

The final step of the process is to copy the dosing tool from the previous year, rename it, and copy the contents of the sheets from the automatically generated file into the new dosing tool.  Unfortunately this process must be done manually.

Note that it is also perfectly fine to generate the farm sheets using a different mechanism, in which case you only need to copy the weather data and coefficients sheets into the new dosing tool.


---

## Long-term support

---

The dosing tool and R package that supports it have been designed to be as robust as possible in the hope that they will continue to function for the foreseeable future. However, if unexpected issues arise in the future (either with the tool or the R package) then please feel free to contact me and I will try to help!



---

## Vignette

This static vignette was built with:

---

```{r}
sessionInfo()
```

To rebuild the vignette, find the 'DonkeyDosing.Rmd' file in the 'vignette_source' directory (inside the inst directory of the package tarball), and (after editing as necessary) run:

```{r, eval=FALSE}
knitr::knit2html('DonkeyDosing.Rmd')
```

```{r eval=FALSE, include=FALSE}
## Note: this aborts on (expected) errors:
rmarkdown::render('DonkeyDosing.Rmd')
```


This will create an updated html file that can be used to replace the file provided in the vignettes folder of the package.

Note that the necessary data files are not included in this R package, but were provided to the Donkey Sanctuary in May 2023.

```{r echo=FALSE}
unlink("dosing_sheets_2022.xlsx")
unlink("effect_etimates.csv")
unlink("sex_codes.csv")
```

